<!doctype html><html class="not-ready text-sm lg:text-base" style=--bg:#fbfbfb lang=en>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<title>PassFace: Face Recognition Using OpenCV - Mehmet Ozan Ünal</title>
<meta name=theme-color>
<meta name=description content="Hi,
PassFace is a face recognizing program develop using EmguCV (OpenCV wrapper). It is possible to use 4 different algorithm and 3 different source(Camera, Video, Image) in this program. Most of the tryings have been made using LFW data set which have 13000 pictures of 1500 different people.Details of project can be reached below:
Source Code: https://github.com/mozanunal/PassFace
{% youtube d6LI42NEZZY? %}
1. Introduction Definition of the Problem In this project, a program is going to develop to recognize the faces and compare them the faces it learned and give the identity of the person.">
<meta name=author content="Mehmet Ozan Ünal">
<link rel="preload stylesheet" as=style href=https://mozanunal.com/main.min.css>
<link rel=preload as=image href=https://mozanunal.com/theme.png>
<link rel=preload as=image href="https://www.gravatar.com/avatar/998cbd3ab655239d8be787580cce0415?s=160&d=identicon">
<link rel=preload as=image href=https://mozanunal.com/twitter.svg>
<link rel=preload as=image href=https://mozanunal.com/github.svg>
<link rel=icon href=https://mozanunal.com/favicon.ico>
<link rel=apple-touch-icon href=https://mozanunal.com/apple-touch-icon.png>
<meta name=generator content="Hugo 0.92.2">
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','G-N3F3XLS474','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-N3F3XLS474"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-N3F3XLS474',{anonymize_ip:!1})}</script>
<meta property="og:title" content="PassFace: Face Recognition Using OpenCV">
<meta property="og:description" content="Hi,
PassFace is a face recognizing program develop using EmguCV (OpenCV wrapper). It is possible to use 4 different algorithm and 3 different source(Camera, Video, Image) in this program. Most of the tryings have been made using LFW data set which have 13000 pictures of 1500 different people.Details of project can be reached below:
Source Code: https://github.com/mozanunal/PassFace
{% youtube d6LI42NEZZY? %}
1. Introduction Definition of the Problem In this project, a program is going to develop to recognize the faces and compare them the faces it learned and give the identity of the person.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://mozanunal.com/2016/06/passface-face-recognition-using-opencv/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2016-06-04T19:50:00+00:00">
<meta property="article:modified_time" content="2016-06-04T19:50:00+00:00">
<meta itemprop=name content="PassFace: Face Recognition Using OpenCV">
<meta itemprop=description content="Hi,
PassFace is a face recognizing program develop using EmguCV (OpenCV wrapper). It is possible to use 4 different algorithm and 3 different source(Camera, Video, Image) in this program. Most of the tryings have been made using LFW data set which have 13000 pictures of 1500 different people.Details of project can be reached below:
Source Code: https://github.com/mozanunal/PassFace
{% youtube d6LI42NEZZY? %}
1. Introduction Definition of the Problem In this project, a program is going to develop to recognize the faces and compare them the faces it learned and give the identity of the person."><meta itemprop=datePublished content="2016-06-04T19:50:00+00:00">
<meta itemprop=dateModified content="2016-06-04T19:50:00+00:00">
<meta itemprop=wordCount content="1458">
<meta itemprop=keywords content="Image Processing,EmguCV,opencv,Eigenfaces,Face recognition,Fisgerfaces,">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="PassFace: Face Recognition Using OpenCV">
<meta name=twitter:description content="Hi,
PassFace is a face recognizing program develop using EmguCV (OpenCV wrapper). It is possible to use 4 different algorithm and 3 different source(Camera, Video, Image) in this program. Most of the tryings have been made using LFW data set which have 13000 pictures of 1500 different people.Details of project can be reached below:
Source Code: https://github.com/mozanunal/PassFace
{% youtube d6LI42NEZZY? %}
1. Introduction Definition of the Problem In this project, a program is going to develop to recognize the faces and compare them the faces it learned and give the identity of the person.">
</head>
<body class="text-black duration-200 ease-out dark:text-white">
<header class="mx-auto flex h-[5rem] max-w-3xl px-8 lg:justify-center">
<div class="relative z-50 mr-auto flex items-center">
<a class="-translate-x-[1px] -translate-y-0.5 text-3xl font-bold" href=https://mozanunal.com/>Mehmet Ozan Ünal</a>
<div class="btn-dark text-[0] ml-6 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.svg)_left_center/cover_no-repeat] dark:invert dark:[background-position:right]" role=button aria-label=Dark></div>
</div>
<div class="btn-menu relative z-50 -mr-8 flex h-[5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden" role=button aria-label=Menu></div>
<script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove('not-ready')},10);const btnMenu=document.querySelector('.btn-menu');btnMenu.addEventListener('click',()=>{htmlClass.toggle('open')});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg=`"#fbfbfb"`.replace(/"/g,''),setDark=a=>{metaTheme.setAttribute('content',a?'#000':lightBg),htmlClass[a?'add':'remove']('dark'),localStorage.setItem('dark',a)},darkScheme=window.matchMedia('(prefers-color-scheme: dark)');if(htmlClass.contains('dark'))setDark(!0);else{const a=localStorage.getItem('dark');setDark(a?a==='true':darkScheme.matches)}darkScheme.addEventListener('change',a=>{setDark(a.matches)});const btnDark=document.querySelector('.btn-dark');btnDark.addEventListener('click',()=>{setDark(localStorage.getItem('dark')!=='true')})</script>
<div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none">
<nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6">
<a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href=/about/>About</a>
<a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href=/contact/>Contact</a>
</nav>
<nav class="mt-12 flex justify-center space-x-10 dark:invert lg:mt-0 lg:ml-12 lg:items-center lg:space-x-6">
<a class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./twitter.svg) href=https://twitter.com/MOzanUnal target=_blank rel=me>
twitter
</a>
<a class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./github.svg) href=https://github.com/mozanunal target=_blank rel=me>
github
</a>
</nav>
</div>
</header>
<main class="prose prose-neutral relative mx-auto min-h-[calc(100%-10rem)] max-w-3xl px-8 pt-16 pb-24 dark:prose-invert">
<article>
<header class=mb-20>
<h1 class="!my-0 pb-2.5">PassFace: Face Recognition Using OpenCV</h1>
<div class="text-sm opacity-60">
<time>Jun 4, 2016</time>
<span class=mx-1>&#183;</span>
<span>Mehmet Ozan Ünal</span>
</div>
</header>
<section><p><strong>Hi,</strong><br>
PassFace is a face recognizing program develop using EmguCV (OpenCV wrapper). It is possible to use 4 different algorithm and 3 different source(Camera, Video, Image) in this program. Most of the tryings have been made using LFW data set which have 13000 pictures of 1500 different people.Details of project can be reached below:</p>
<p>Source Code: <a href=https://github.com/mozanunal/PassFace>https://github.com/mozanunal/PassFace</a></p>
<p>{% youtube d6LI42NEZZY? %}</p>
<h4 id=1-introduction>1. Introduction</h4>
<h5 id=definition-of-the-problem>Definition of the Problem</h5>
<p>In this project, a program is going to develop to recognize the faces and compare them the faces it learned and give the identity of the person. All this identifying system is going to work in real time. Main subjects in this project are image processing and machine learning. Project aim to develop some algorithm to detect faces specifically recognize the faces using pattern recognition algorithms. The number of faces and the equipment needed is going to be determined according to test of different algorithms.</p>
<h5 id=motivation>Motivation</h5>
<p>To detect identity of person from images is very beneficial subject. It can provide easy access to users. It can be used for detect criminals and prevent potential crimes. Also I see this subject in a lot of industrial projects and academic researches. I want to work with real world problem and problem which is not completely solved. Therefore I decided to work with this project.</p>
<h5 id=difficulties-of-problem>Difficulties of Problem</h5>
<p>Main difficulties can be sorted like below:</p>
<ul>
<li>Faces are not completely rigid objects so it is hard to recognize them.</li>
<li>The more person in database needs more and more processing power.</li>
<li>Blurry images because of real time system</li>
<li>The effects of ambient light</li>
<li>Changes in person’s face over time</li>
</ul>
<h5 id=data-sets>Data Sets</h5>
<p><a href=https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html>AT&T Facedatabase</a></p>
<p>The AT&T Face Database, sometimes also referred to as ORL Database of Faces, contains ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).</p>
<p><a href=https://vision.ucsd.edu/content/yale-face-database>Yale Facedatabase A</a></p>
<p>also known as Yalefaces. The AT&T Face Database is good for initial tests, but it’s a fairly easy database. The Eigenfaces method already has a 97% recognition rate on it, so you won’t see any great improvements with other algorithms. The Yale Face Database A (also known as Yalefaces) is a more appropriate dataset for initial experiments, because the recognition problem is harder. The database consists of 15 people (14 male, 1 female) each with 11 grayscale images sized 320x243 <a href=https://lh3.googleusercontent.com/uNq7mPqspjvR267h-aZA2FS666Fl8Q8dXGhlg-Lzi7MJiNn5DkSyioK59Wj6pdA9h96bojY8L02LR-NIXIeuf0IjN-a6MYN7ufWHMOPqVbxd0hvoGcKsy0oR9jo5t85MGbfqOB9H></a>pixel. There are changes in the light conditions (center light, left light, right light), facial expressions (happy, normal, sad, sleepy, surprised, wink) and glasses (glasses, no-glasses).</p>
<p><a href>Labeled Faces in the Wild</a></p>
<p>A database of face photographs designed for studying the problem of unconstrained face recognition. The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. 1680 of the people pictured have two or more distinct photos in the data set. The only constraint on these faces is that they were detected by the Viola-Jones face detector..</p>
<h5 id=programming-environment-and-libraries>Programming Environment and Libraries</h5>
<p>Visual Studio IDE is used for project. The program is written in C# using OpenCV libraries.</p>
<h4 id=2-face-recognition-algorithm>2. Face Recognition Algorithm</h4>
<h5 id=face-detection>Face Detection</h5>
<p>Face Detection is not the main subject of this project but to create database and to increase the face recognition performance. Opencv’s Haar Cascade Classifier function is used. In this function a haar cascade file ,which is pre learned for face detection, is used.</p>
<h5 id=morphologic-operations>Morphologic Operations</h5>
<p>Ambient light and the movement at faces are the challenging problems in face recognition. Therefore some morphologic operators is applied to the faces to decrease the effect of these problems. In this project equalize histogram function of opencv is used to decrease the effect of the ambient light.<img src=https://lh6.googleusercontent.com/3PMQmXghZyoi4dGekFhBS-QWqZDYEJpQ2o_yLXJgMEo3goTr6OqtrOSPYjtwgApKjKoAzXhFLE57R3TRDw8SWrXsod9PUCiHJXNndjoZ-Ui3P1xb0atKy0EvobLyy9cfVifzA0yT alt></p>
<h5 id=surf-feature-extractor>SURF Feature Extractor</h5>
<p><img src=https://lh5.googleusercontent.com/eRt6xx3RU22fZ22_-TGdan22lp2x7JiNA9De7PuYa2xLVcZIcg4hVJzvrXyzdNbocv4NuBW8QOHYYTr0NNowPys7QOScefuBrgEeoiILasaQm2v0S0P8NPxVYSiPBRoPotTP3h0p alt></p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=color:#ff79c6>if</span> (comboBoxAlgorithm.Text == “SURF Feature Extractor”)
{
<span style=color:#8be9fd>string</span> dataDirectory=Directory.GetCurrentDirectory()+”\TrainedFaces”;
<span style=color:#8be9fd>string</span>[] files = Directory.GetFiles(dataDirectory, “*.jpeg”, SearchOption.AllDirectories);

<span style=color:#ff79c6>foreach</span> (<span style=color:#8be9fd>var</span> file <span style=color:#ff79c6>in</span> files)
{
   richTextBox1.Text += file.ToString();
   <span style=color:#8be9fd>long</span> recpoints;
   ImagesampleImage = <span style=color:#ff79c6>new</span> Image(file);
   secondImageBox.Image = sampleImage;
   <span style=color:#ff79c6>using</span> (Image modelImage = sampleImage.Convert())
   <span style=color:#ff79c6>using</span> (Image observedImage = image.Convert())
   {
       Image result = SurfRecognizer.Draw(modelImage, observedImage, <span style=color:#ff79c6>out</span> recpoints);
       <span style=color:#6272a4>//captureImageBox.Image = observedImage;
</span><span style=color:#6272a4></span>       <span style=color:#ff79c6>if</span> (recpoints &gt; <span style=color:#bd93f9>10</span>)
       {
           MCvFont f = <span style=color:#ff79c6>new</span> MCvFont(Emgu.CV.CvEnum.FONT.CV_FONT_HERSHEY_COMPLEX, <span style=color:#bd93f9>1.0</span>, <span style=color:#bd93f9>1.0</span>);
           result.Draw(“Person Recognited, Welcome”, <span style=color:#ff79c6>ref</span> f, <span style=color:#ff79c6>new</span> Point(<span style=color:#bd93f9>40</span>, <span style=color:#bd93f9>40</span>), <span style=color:#ff79c6>new</span> Bgr(<span style=color:#bd93f9>0</span>, <span style=color:#bd93f9>255</span>, <span style=color:#bd93f9>0</span>));
           ImageViewer.Show(result, String.Format(“ {<span style=color:#bd93f9>0</span>} Points Recognited”, recpoints));
       }
   }
}
</code></pre></div><h5 id=eigenfaces>Eigenfaces</h5>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=color:#ff79c6>else</span> <span style=color:#ff79c6>if</span> (comboBoxAlgorithm.Text == <span style=color:#f1fa8c>&#34;EigenFaces&#34;</span>)
{
   <span style=color:#6272a4>//image._EqualizeHist();
</span><span style=color:#6272a4></span>   <span style=color:#ff79c6>if</span> (eqHisChecked.Checked == <span style=color:#ff79c6>true</span>)
   {
       image.<span style=color:#bd93f9>_</span>EqualizeHist();
   }
   <span style=color:#8be9fd>var</span> result = eigenFaceRecognizer.Predict(image.Convert().Resize(<span style=color:#bd93f9>100</span>, <span style=color:#bd93f9>100</span>, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC));
   <span style=color:#ff79c6>if</span> (result.Label != -<span style=color:#bd93f9>1</span>)
   {
       image.Draw(eigenlabels[result.Label].ToString(), <span style=color:#ff79c6>ref</span> font, <span style=color:#ff79c6>new</span> Point(face.X - <span style=color:#bd93f9>2</span>, face.Y - <span style=color:#bd93f9>2</span>), <span style=color:#ff79c6>new</span> Bgr(Color.LightGreen));
       label6.Text = result.Distance.ToString();
   }
}
</code></pre></div><h5 id=fisherfaces>Fisherfaces</h5>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp>
<span style=color:#ff79c6>else</span> <span style=color:#ff79c6>if</span> (comboBoxAlgorithm.Text == <span style=color:#f1fa8c>&#34;FisherFaces&#34;</span>)
{
   <span style=color:#ff79c6>if</span> (eqHisChecked.Checked == <span style=color:#ff79c6>true</span>)
   {
       image.<span style=color:#bd93f9>_</span>EqualizeHist();
   }
   <span style=color:#8be9fd>var</span> result = fisherFaceRecognizer.Predict(image.Convert().Resize(<span style=color:#bd93f9>100</span>, <span style=color:#bd93f9>100</span>, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC));
   <span style=color:#ff79c6>if</span> (result.Label != -<span style=color:#bd93f9>1</span>)
   {
       image.Draw(fisherlabels[result.Label].ToString(), <span style=color:#ff79c6>ref</span> font, <span style=color:#ff79c6>new</span> Point(face.X - <span style=color:#bd93f9>2</span>, face.Y - <span style=color:#bd93f9>2</span>), <span style=color:#ff79c6>new</span> Bgr(Color.LightGreen));
       label6.Text = result.Distance.ToString();
   }


}
</code></pre></div><h5 id=local-binary-patterns-histograms>Local Binary Patterns Histograms</h5>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=color:#ff79c6>else</span> <span style=color:#ff79c6>if</span> (comboBoxAlgorithm.Text == <span style=color:#f1fa8c>&#34;LBPHFaces&#34;</span>)
{
   <span style=color:#ff79c6>if</span> (eqHisChecked.Checked == <span style=color:#ff79c6>true</span>)
   {
       image.<span style=color:#bd93f9>_</span>EqualizeHist();
   }
   <span style=color:#8be9fd>var</span> result = lbphFaceRecognizer.Predict(image.Convert().Resize(<span style=color:#bd93f9>100</span>, <span style=color:#bd93f9>100</span>, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC));
   <span style=color:#ff79c6>if</span> (result.Label != -<span style=color:#bd93f9>1</span>)
   {
       image.Draw(lbphlabels[result.Label].ToString(), <span style=color:#ff79c6>ref</span> font, <span style=color:#ff79c6>new</span> Point(face.X - <span style=color:#bd93f9>2</span>, face.Y - <span style=color:#bd93f9>2</span>), <span style=color:#ff79c6>new</span> Bgr(Color.LightGreen));
       label6.Text = result.Distance.ToString();
   }
}
</code></pre></div><h4 id=3-passface-interface>3. PassFace Interface</h4>
<h5 id=database-creator>Database Creator</h5>
<p>A database creator is developed to make easier to implement and try different algorithm.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp>Add DataBase Function


<span style=color:#ff79c6>private</span> <span style=color:#ff79c6>void</span> addDatabaseButton_Click(<span style=color:#8be9fd>object</span> sender, EventArgs e)
{
   <span style=color:#6272a4>//Take time for save filename
</span><span style=color:#6272a4></span>   <span style=color:#8be9fd>string</span> fileName = textBox1.Text+<span style=color:#f1fa8c>&#34;_&#34;</span>+DateTime.Now.Day.ToString() + <span style=color:#f1fa8c>&#34;-&#34;</span> + DateTime.Now.Month.ToString() + <span style=color:#f1fa8c>&#34;-&#34;</span> + DateTime.Now.Year.ToString()
   + <span style=color:#f1fa8c>&#34;-&#34;</span> + DateTime.Now.Hour.ToString() + <span style=color:#f1fa8c>&#34;-&#34;</span> + DateTime.Now.Minute.ToString()+<span style=color:#f1fa8c>&#34;-&#34;</span> + DateTime.Now.Second.ToString()+<span style=color:#f1fa8c>&#34;.jpeg&#34;</span>;

   <span style=color:#6272a4>//First The faces in the Image is detected
</span><span style=color:#6272a4></span>   Image image = <span style=color:#bd93f9>_</span>capture.RetrieveBgrFrame().Resize(<span style=color:#bd93f9>400</span>, <span style=color:#bd93f9>300</span>, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
   List faces = <span style=color:#ff79c6>new</span> List();
   List eyes = <span style=color:#ff79c6>new</span> List();
   <span style=color:#8be9fd>long</span> detectionTime;
   DetectFace.Detect(image, <span style=color:#f1fa8c>&#34;haarcascade_frontalface_default.xml&#34;</span>, <span style=color:#f1fa8c>&#34;haarcascade_eye.xml&#34;</span>, faces, eyes, <span style=color:#ff79c6>out</span> detectionTime);
   <span style=color:#ff79c6>foreach</span> (Rectangle face <span style=color:#ff79c6>in</span> faces)
   {
       image.ROI = face;
   }
   Directory.CreateDirectory(<span style=color:#f1fa8c>&#34;TrainedFaces&#34;</span>);
   image.Resize(<span style=color:#bd93f9>100</span>, <span style=color:#bd93f9>100</span>, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC).ToBitmap().Save(<span style=color:#f1fa8c>&#34;TrainedFaces\\&#34;</span> + fileName);
}


<span style=color:#ff79c6>private</span> <span style=color:#ff79c6>void</span> comboBoxAlgorithm_SelectedIndexChanged(<span style=color:#8be9fd>object</span> sender, EventArgs e)
{
   <span style=color:#ff79c6>if</span> (comboBoxAlgorithm.Text == <span style=color:#f1fa8c>&#34;EigenFaces&#34;</span>)
   {
       <span style=color:#ff79c6>try</span>
       {
         <span style=color:#8be9fd>string</span> dataDirectory = Directory.GetCurrentDirectory() + <span style=color:#f1fa8c>&#34;\\TrainedFaces&#34;</span>;
         <span style=color:#8be9fd>string</span>[] files = Directory.GetFiles(dataDirectory, <span style=color:#f1fa8c>&#34;*.jpeg&#34;</span>, SearchOption.AllDirectories);
         eigenTrainedImageCounter = <span style=color:#bd93f9>0</span>;
         <span style=color:#ff79c6>foreach</span> (<span style=color:#8be9fd>var</span> file <span style=color:#ff79c6>in</span> files)
         {
               Image TrainedImage=<span style=color:#ff79c6>new</span> Image(file);
               <span style=color:#ff79c6>if</span> (eqHisChecked.Checked == <span style=color:#ff79c6>true</span>)
               {
                   TrainedImage.<span style=color:#bd93f9>_</span>EqualizeHist();
               }
               eigenTrainingImages.Add(TrainedImage.Convert());
               eigenlabels.Add(fileName(file));
               eigenIntlabels.Add(eigenTrainedImageCounter);
               eigenTrainedImageCounter++;
               richTextBox1.Text += fileName(file)+<span style=color:#f1fa8c>&#34;\n&#34;</span>;
         }
          eigenFaceRecognizer= <span style=color:#ff79c6>new</span> EigenFaceRecognizer(eigenTrainedImageCounter, <span style=color:#bd93f9>3000</span>);
          eigenFaceRecognizer.Train(eigenTrainingImages.ToArray(), eigenIntlabels.ToArray());
            
       }
       <span style=color:#ff79c6>catch</span> (Exception ex)
       {
           MessageBox.Show(ex.ToString());
           MessageBox.Show(<span style=color:#f1fa8c>&#34;Nothing in binary database, please add at least a face(Simply train the prototype with the Add Face Button).&#34;</span>, <span style=color:#f1fa8c>&#34;Triained faces load&#34;</span>, MessageBoxButtons.OK, MessageBoxIcon.Exclamation);
       }
   }
   <span style=color:#ff79c6>else</span> <span style=color:#ff79c6>if</span> (comboBoxAlgorithm.Text == <span style=color:#f1fa8c>&#34;FisherFaces&#34;</span>)
   {
       <span style=color:#ff79c6>try</span>
       {
           <span style=color:#8be9fd>string</span> dataDirectory = Directory.GetCurrentDirectory() + <span style=color:#f1fa8c>&#34;\\TrainedFaces&#34;</span>;
           <span style=color:#8be9fd>string</span>[] files = Directory.GetFiles(dataDirectory, <span style=color:#f1fa8c>&#34;*.jpeg&#34;</span>, SearchOption.AllDirectories);
           fisherTrainedImageCounter = <span style=color:#bd93f9>0</span>;
           <span style=color:#ff79c6>foreach</span> (<span style=color:#8be9fd>var</span> file <span style=color:#ff79c6>in</span> files)
           {
               Image TrainedImage = <span style=color:#ff79c6>new</span> Image(file);
               fisherTrainingImages.Add(TrainedImage.Convert());
               <span style=color:#ff79c6>if</span> (eqHisChecked.Checked == <span style=color:#ff79c6>true</span>)
               {
                   TrainedImage.<span style=color:#bd93f9>_</span>EqualizeHist();
               }
               fisherlabels.Add(fileName(file));
               fisherIntlabels.Add(fisherTrainedImageCounter);
               fisherTrainedImageCounter++;
               richTextBox1.Text += fileName(file) + <span style=color:#f1fa8c>&#34;\n&#34;</span>;
           }
           fisherFaceRecognizer = <span style=color:#ff79c6>new</span> FisherFaceRecognizer(fisherTrainedImageCounter, <span style=color:#bd93f9>3000</span>);
           fisherFaceRecognizer.Train(fisherTrainingImages.ToArray(), fisherIntlabels.ToArray());
       }
       <span style=color:#ff79c6>catch</span> (Exception ex)
       {
           MessageBox.Show(ex.ToString());
           MessageBox.Show(<span style=color:#f1fa8c>&#34;Nothing in binary database, please add at least a face(Simply train the prototype with the Add Face Button).&#34;</span>, <span style=color:#f1fa8c>&#34;Triained faces load&#34;</span>, MessageBoxButtons.OK, MessageBoxIcon.Exclamation);
       }
   }
   <span style=color:#ff79c6>else</span> <span style=color:#ff79c6>if</span> (comboBoxAlgorithm.Text == <span style=color:#f1fa8c>&#34;LBPHFaces&#34;</span>)
   {
       <span style=color:#ff79c6>try</span>
       {
           <span style=color:#8be9fd>string</span> dataDirectory = Directory.GetCurrentDirectory() + <span style=color:#f1fa8c>&#34;\\TrainedFaces&#34;</span>;
           <span style=color:#8be9fd>string</span>[] files = Directory.GetFiles(dataDirectory, <span style=color:#f1fa8c>&#34;*.jpeg&#34;</span>, SearchOption.AllDirectories);
           lbphTrainedImageCounter = <span style=color:#bd93f9>0</span>;
           <span style=color:#ff79c6>foreach</span> (<span style=color:#8be9fd>var</span> file <span style=color:#ff79c6>in</span> files)
           {
               Image TrainedImage = <span style=color:#ff79c6>new</span> Image(file);
               <span style=color:#ff79c6>if</span> (eqHisChecked.Checked == <span style=color:#ff79c6>true</span>)
               {
                   TrainedImage.<span style=color:#bd93f9>_</span>EqualizeHist();
               }
               lbphTrainingImages.Add(TrainedImage.Convert());
               lbphlabels.Add(fileName(file));
               lbphIntlabels.Add(lbphTrainedImageCounter);
               lbphTrainedImageCounter++;
               richTextBox1.Text += fileName(file) + <span style=color:#f1fa8c>&#34;\n&#34;</span>;
           }
           lbphFaceRecognizer = <span style=color:#ff79c6>new</span> LBPHFaceRecognizer(<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>8</span>, <span style=color:#bd93f9>8</span>, <span style=color:#bd93f9>8</span>, <span style=color:#bd93f9>123.0</span>);
           lbphFaceRecognizer.Train(lbphTrainingImages.ToArray(), lbphIntlabels.ToArray());
       }
       <span style=color:#ff79c6>catch</span> (Exception ex)
       {
           MessageBox.Show(ex.ToString());
           MessageBox.Show(<span style=color:#f1fa8c>&#34;Nothing in binary database, please add at least a face(Simply train the prototype with the Add Face Button).&#34;</span>, <span style=color:#f1fa8c>&#34;Triained faces load&#34;</span>, MessageBoxButtons.OK, MessageBoxIcon.Exclamation);
       }
   }
}

</code></pre></div><p><img src=https://lh4.googleusercontent.com/560MflmHrYy5nUi4gIAQexc-Cdqfyr3GUej_g1wwa0HawxO4A7OFmOkgd0g4oBvy9An1PjiYxSM_8G0G2FS_zC2y3gWisgkr0NTikxv4oyDFL9qM6IpkupdhA7OjnUAb4cuy51Pa alt></p>
<h5 id=user-interface>User Interface</h5>
<p>As a source camera, video, single image and multi image can be selected. Different source selection is developed using opencv and .net libraries.</p>
<p><img src=https://lh5.googleusercontent.com/6y8Sx-7a4PDYcZWv9W_COKJf9EaGKQl-_3vc6q9oo-HzQeC4CJMJoGTceeaUAC4F31mjpGs84Zrkse1viHgwCCKnRvhciz7aEjmmySR16PAD2aOGmOrLWHr6R3hO7GvV0TamI9nS alt></p>
<h4 id=4-future-of-passface-project>4. Future of PassFace Project</h4>
<h5 id=algorithm-accuracy-analysis>Algorithm Accuracy Analysis</h5>
<p>Program designed for using different algorithms. But the comparison of these algorithms is not finished. The next step is implementing this algorithm the compare the algorithms accuracy and performance truly.</p>
<h5 id=performance-optimizations>Performance Optimizations</h5>
<p>For fix the performance problems, develop the program for multiple core CPUs. For better performance, develop the program to run over GPU using CUDA libraries.</p>
<h5 id=algorithm-optimizations>Algorithm Optimizations</h5>
<p>In these days, the most improved face recognition algorithms are using 3D face recognition technologies. It is based on; the 3D model of the faces are created using different 2D images. Therefore, the angle of looking and the direction of light are no longer be problem for these algorithms. The recognize operations are implementing using Neural Networks and Deep Learning Algorithms. It is planning to implement latest algorithms to increase accuracy in different conditions.</p>
<h4 id=5-conclusion>5. Conclusion</h4>
<p>In this project, the main principles of the face recognition algorithms are learned. The performances and accuracies of the algorithms are compared. A gui application is developed to create database and process images using selected algorithm.</p>
</section>
<footer class="mt-12 flex flex-wrap">
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=https://mozanunal.com/tags/image-processing>Image Processing</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=https://mozanunal.com/tags/emgucv>EmguCV</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=https://mozanunal.com/tags/opencv>opencv</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=https://mozanunal.com/tags/eigenfaces>Eigenfaces</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=https://mozanunal.com/tags/face-recognition>Face recognition</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=https://mozanunal.com/tags/fisgerfaces>Fisgerfaces</a>
</footer>
<nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]">
<a class="flex w-1/2 items-center rounded-l-md p-6 pr-3 no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]" href=https://mozanunal.com/2016/06/wpf-ile-ev-otomasyonu-arayuzu/><span class=mr-1.5>←</span><span>[TR] WPF ile Ev Otomasyonu Arayüzü</span></a>
<a class="ml-auto flex w-1/2 items-center justify-end rounded-r-md p-6 pl-3 no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]" href=https://mozanunal.com/2016/05/simplecv-ile-goruntu-islemeye-giris/><span>[TR] SimpleCV ile Görüntü İşlemeye Giriş</span><span class=ml-1.5>→</span></a>
</nav>
</article>
</main>
<footer class="opaco mx-auto flex h-[5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60">
<div class=mr-auto>
&copy; 2023
<a class=link href=https://mozanunal.com/>Mehmet Ozan Ünal</a>
</div>
<a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>Powered by Hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>Theme Paper</a>
</footer>
</body>
</html>